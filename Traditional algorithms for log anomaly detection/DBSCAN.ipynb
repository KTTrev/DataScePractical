{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = pd.read_csv(\"Training_day_9.txt\", sep = \",\", na_values = ['?','.'])\n",
    "dataset_test = pd.read_csv(\"Test_day_9.txt\", sep = \",\", na_values = ['?','.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train = dataset_train.drop('Unnamed: 0',1)\n",
    "dataset_test = dataset_test.drop('Unnamed: 0',1)\n",
    "# dataset_train = dataset_train.drop('time',1)\n",
    "dataset_test = dataset_test.drop('time',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([dataset_train, dataset_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = data['Malignant/Benign'] # will be resused for the confusion matrix\n",
    "data = data.drop('Malignant/Benign', 1) # because the model is Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing using factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,0] = pd.factorize(data.iloc[:,0])[0]\n",
    "data.iloc[:,1] = pd.factorize(data.iloc[:,1])[0]\n",
    "data.iloc[:,2] = pd.factorize(data.iloc[:,2])[0]\n",
    "data.iloc[:,3] = pd.factorize(data.iloc[:,3])[0]\n",
    "data.iloc[:,4] = pd.factorize(data.iloc[:,4])[0]\n",
    "data.iloc[:,5] = pd.factorize(data.iloc[:,5])[0]\n",
    "data.iloc[:,6] = pd.factorize(data.iloc[:,6])[0]\n",
    "data.iloc[:,7] = pd.factorize(data.iloc[:,7])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevor/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "data['source_user@domain'] = MinMaxScaler(feature_range= (0,1)).fit_transform(data['source_user@domain'].values.reshape(-1, 1))\n",
    "data['destination_user@domain'] = MinMaxScaler(feature_range= (0,1)).fit_transform(data['destination_user@domain'].values.reshape(-1, 1))\n",
    "data['source_computer'] = MinMaxScaler(feature_range= (0,1)).fit_transform(data['source_computer'].values.reshape(-1, 1))\n",
    "data['destination_computer'] = MinMaxScaler(feature_range= (0,1)).fit_transform(data['destination_computer'].values.reshape(-1, 1))\n",
    "data['authentication_type'] = MinMaxScaler(feature_range= (0,1)).fit_transform(data['authentication_type'].values.reshape(-1, 1))\n",
    "data['logon_type'] = MinMaxScaler(feature_range= (0,1)).fit_transform(data['logon_type'].values.reshape(-1, 1))\n",
    "data['authentication_orientation'] = MinMaxScaler(feature_range= (0,1)).fit_transform(data['authentication_orientation'].values.reshape(-1, 1))\n",
    "data['success/failure'] = MinMaxScaler(feature_range= (0,1)).fit_transform(data['success/failure'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detection = DBSCAN(min_samples = 3, eps = 3)\n",
    "clusters = outlier_detection.fit_predict(data)\n",
    "list(clusters).count(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 is outlier, i.e. what we hope to be the anomaly\n",
    "TP = np.sum((anomaly == 1) & (clusters == -1))\n",
    "FN = np.sum((anomaly == 1) & (clusters != -1))\n",
    "FP = np.sum((anomaly == 0) & (clusters == -1))\n",
    "TN = np.sum((anomaly == 0) & (clusters != -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  200\n",
      "FN:  0\n",
      "FP:  0\n",
      "TN:  10000\n"
     ]
    }
   ],
   "source": [
    "print (\"TP: \", TP)\n",
    "print (\"FN: \", FN)\n",
    "print (\"FP: \", FP)\n",
    "print (\"TN: \", TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "recall:  1.0\n",
      "Specificity:  1.0\n",
      "precision:  1.0\n",
      "F1:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Performance Matrix\n",
    "\n",
    "# Performance Matrix\n",
    "accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "print (\"Accuracy: \", np.round(accuracy, 2))\n",
    "recall = TP/(TP+FN)\n",
    "print (\"recall: \", np.round(recall, 2))\n",
    "specificity = TN/(TN+FP)\n",
    "print (\"Specificity: \", np.round(specificity, 2))\n",
    "precision = TP/(TP + FP)\n",
    "print (\"precision: \", np.round(precision, 2))\n",
    "F1 = 2/((1/precision) + (1/recall))\n",
    "print (\"F1: \", np.round(F1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "random_data = np.random.randn(50000,2)  * 20 + 20\n",
    "\n",
    "outlier_detection = DBSCAN(min_samples = 2, eps = 3)\n",
    "clusters = outlier_detection.fit_predict(random_data)\n",
    "list(clusters).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clusters).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
