{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The datasets used here are day_9_ttaining_final_2.txt and day_9_test_new.txt, should be renamed as Training_day_9.txt and Test_day_9.txt respectively in order to run the code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(\"Training_day_9.txt\", sep = \",\", na_values = ['?','.'])\n",
    "dataset_test = pd.read_csv(\"Test_day_9.txt\", sep = \",\", na_values = ['?','.'])\n",
    "\n",
    "# dataset_train = dataset_train.drop('Unnamed: 0',1)\n",
    "# dataset_test = dataset_test.drop('Unnamed: 0',1)\n",
    "dataset_train = dataset_train.drop('time',1)\n",
    "dataset_test = dataset_test.drop('time',1)\n",
    "dataset_train.rename(columns={'anomaly':'Malignant/Benign'}, inplace=True)\n",
    "dataset_test.rename(columns={'anomaly':'Malignant/Benign'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_user@domain</th>\n",
       "      <th>destination_user@domain</th>\n",
       "      <th>source_computer</th>\n",
       "      <th>destination_computer</th>\n",
       "      <th>authentication_type</th>\n",
       "      <th>logon_type</th>\n",
       "      <th>authentication_orientation</th>\n",
       "      <th>success</th>\n",
       "      <th>Malignant/Benign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U1653@DOM1</td>\n",
       "      <td>U1653@DOM1</td>\n",
       "      <td>C17693</td>\n",
       "      <td>C395</td>\n",
       "      <td>NTLM</td>\n",
       "      <td>Network</td>\n",
       "      <td>LogOn</td>\n",
       "      <td>Success</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U2164@DOM1</td>\n",
       "      <td>U2164@DOM1</td>\n",
       "      <td>C6438</td>\n",
       "      <td>C2382</td>\n",
       "      <td>Kerberos</td>\n",
       "      <td>Network</td>\n",
       "      <td>LogOn</td>\n",
       "      <td>Success</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U7988@DOM1</td>\n",
       "      <td>U7988@DOM1</td>\n",
       "      <td>C2039</td>\n",
       "      <td>C457</td>\n",
       "      <td>Kerberos</td>\n",
       "      <td>Network</td>\n",
       "      <td>LogOn</td>\n",
       "      <td>Success</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1708$@DOM1</td>\n",
       "      <td>C1708$@DOM1</td>\n",
       "      <td>C1709</td>\n",
       "      <td>C528</td>\n",
       "      <td>Kerberos</td>\n",
       "      <td>Network</td>\n",
       "      <td>LogOn</td>\n",
       "      <td>Success</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C11388$@DOM1</td>\n",
       "      <td>C11388$@DOM1</td>\n",
       "      <td>C11388</td>\n",
       "      <td>C529</td>\n",
       "      <td>Kerberos</td>\n",
       "      <td>Network</td>\n",
       "      <td>LogOn</td>\n",
       "      <td>Success</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_user@domain destination_user@domain source_computer  \\\n",
       "0         U1653@DOM1              U1653@DOM1          C17693   \n",
       "1         U2164@DOM1              U2164@DOM1           C6438   \n",
       "2         U7988@DOM1              U7988@DOM1           C2039   \n",
       "3        C1708$@DOM1             C1708$@DOM1           C1709   \n",
       "4       C11388$@DOM1            C11388$@DOM1          C11388   \n",
       "\n",
       "  destination_computer authentication_type logon_type  \\\n",
       "0                 C395                NTLM    Network   \n",
       "1                C2382            Kerberos    Network   \n",
       "2                 C457            Kerberos    Network   \n",
       "3                 C528            Kerberos    Network   \n",
       "4                 C529            Kerberos    Network   \n",
       "\n",
       "  authentication_orientation  success  Malignant/Benign  \n",
       "0                      LogOn  Success                 1  \n",
       "1                      LogOn  Success                 0  \n",
       "2                      LogOn  Success                 0  \n",
       "3                      LogOn  Success                 0  \n",
       "4                      LogOn  Success                 0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.iloc[:,0] = pd.factorize(dataset_train.iloc[:,0])[0]\n",
    "dataset_train.iloc[:,1] = pd.factorize(dataset_train.iloc[:,1])[0]\n",
    "dataset_train.iloc[:,2] = pd.factorize(dataset_train.iloc[:,2])[0]\n",
    "dataset_train.iloc[:,3] = pd.factorize(dataset_train.iloc[:,3])[0]\n",
    "dataset_train.iloc[:,4] = pd.factorize(dataset_train.iloc[:,4])[0]\n",
    "dataset_train.iloc[:,5] = pd.factorize(dataset_train.iloc[:,5])[0]\n",
    "dataset_train.iloc[:,6] = pd.factorize(dataset_train.iloc[:,6])[0]\n",
    "dataset_train.iloc[:,7] = pd.factorize(dataset_train.iloc[:,7])[0]\n",
    "dataset_train.iloc[:,8] = pd.factorize(dataset_train.iloc[:,8])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.iloc[:,0] = pd.factorize(dataset_test.iloc[:,0])[0]\n",
    "dataset_test.iloc[:,1] = pd.factorize(dataset_test.iloc[:,1])[0]\n",
    "dataset_test.iloc[:,2] = pd.factorize(dataset_test.iloc[:,2])[0]\n",
    "dataset_test.iloc[:,3] = pd.factorize(dataset_test.iloc[:,3])[0]\n",
    "dataset_test.iloc[:,4] = pd.factorize(dataset_test.iloc[:,4])[0]\n",
    "dataset_test.iloc[:,5] = pd.factorize(dataset_test.iloc[:,5])[0]\n",
    "dataset_test.iloc[:,6] = pd.factorize(dataset_test.iloc[:,6])[0]\n",
    "dataset_test.iloc[:,7] = pd.factorize(dataset_test.iloc[:,7])[0]\n",
    "dataset_test.iloc[:,8] = pd.factorize(dataset_test.iloc[:,8])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing and Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevor/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset_train['source_user@domain'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['source_user@domain'].values.reshape(-1, 1))\n",
    "dataset_train['destination_user@domain'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['destination_user@domain'].values.reshape(-1, 1))\n",
    "dataset_train['source_computer'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['source_computer'].values.reshape(-1, 1))\n",
    "dataset_train['destination_computer'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['destination_computer'].values.reshape(-1, 1))\n",
    "dataset_train['authentication_type'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['authentication_type'].values.reshape(-1, 1))\n",
    "dataset_train['logon_type'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['logon_type'].values.reshape(-1, 1))\n",
    "dataset_train['authentication_orientation'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['authentication_orientation'].values.reshape(-1, 1))\n",
    "dataset_train['success'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['success'].values.reshape(-1, 1))\n",
    "dataset_train['Malignant/Benign'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_train['Malignant/Benign'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevor/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset_test['source_user@domain'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['source_user@domain'].values.reshape(-1, 1))\n",
    "dataset_test['destination_user@domain'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['destination_user@domain'].values.reshape(-1, 1))\n",
    "dataset_test['source_computer'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['source_computer'].values.reshape(-1, 1))\n",
    "dataset_test['destination_computer'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['destination_computer'].values.reshape(-1, 1))\n",
    "dataset_test['authentication_type'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['authentication_type'].values.reshape(-1, 1))\n",
    "dataset_test['logon_type'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['logon_type'].values.reshape(-1, 1))\n",
    "dataset_test['authentication_orientation'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['authentication_orientation'].values.reshape(-1, 1))\n",
    "dataset_test['success'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['success'].values.reshape(-1, 1))\n",
    "dataset_test['success'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['success'].values.reshape(-1, 1))\n",
    "dataset_test['Malignant/Benign'] = MinMaxScaler(feature_range= (0,1)).fit_transform(dataset_test['Malignant/Benign'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = dataset_train.drop('Malignant/Benign', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dataset_test.drop('Malignant/Benign', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneclass = svm.OneClassSVM(degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test= dataset_test\n",
    "\n",
    "#Y_test is used to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in 1063.13s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "oneclass.fit(train_feature)\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"Training in %.2fs\" % (stop_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction run in 21.02s\n"
     ]
    }
   ],
   "source": [
    "# Test the algorithm on the test set\n",
    "start_time = time.time()\n",
    "\n",
    "fraud_pred = oneclass.predict(X_test)\n",
    "\n",
    "stop_time = time.time()\n",
    "print(\"Prediction run in %.2fs\" % (stop_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1 6245]\n",
      " [   1 3955]]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of outliers predicted by the algorithm\n",
    "\n",
    "unique, counts = np.unique(fraud_pred, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert fraud_pred to dataframe for ease of operation\n",
    "\n",
    "fraud_pred = pd.DataFrame(fraud_pred)\n",
    "fraud_pred= fraud_pred.rename(columns={0: 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "0          -1\n",
       "1          -1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_pred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 is outlier, i.e. what we hope to be the anomaly\n",
    "TP = np.sum((Y_test['Malignant/Benign'] == 1) & (fraud_pred['prediction'] == -1))\n",
    "FN = np.sum((Y_test['Malignant/Benign'] == 1) & (fraud_pred['prediction'] == 1))\n",
    "FP = np.sum((Y_test['Malignant/Benign'] == 0) & (fraud_pred['prediction'] == -1))\n",
    "TN = np.sum((Y_test['Malignant/Benign'] == 0) & (fraud_pred['prediction'] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  6061\n",
      "FN:  3939\n",
      "FP:  184\n",
      "TN:  16\n"
     ]
    }
   ],
   "source": [
    "print (\"TP: \", TP)\n",
    "print (\"FN: \", FN)\n",
    "print (\"FP: \", FP)\n",
    "print (\"TN: \", TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6\n",
      "recall:  0.61\n",
      "Specificity:  0.08\n",
      "precision:  0.97\n",
      "F1:  0.75\n"
     ]
    }
   ],
   "source": [
    "# Performance Matrix\n",
    "\n",
    "# Performance Matrix\n",
    "accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "print (\"Accuracy: \", np.round(accuracy, 2))\n",
    "recall = TP/(TP+FN)\n",
    "print (\"recall: \", np.round(recall, 2))\n",
    "specificity = TN/(TN+FP)\n",
    "print (\"Specificity: \", np.round(specificity, 2))\n",
    "precision = TP/(TP + FP)\n",
    "print (\"precision: \", np.round(precision, 2))\n",
    "F1 = 2/((1/precision) + (1/recall))\n",
    "print (\"F1: \", np.round(F1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change the kernel to check if the result can get better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneclass = svm.OneClassSVM(kernel='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto',\n",
       "      kernel='sigmoid', max_iter=-1, nu=0.5, random_state=None,\n",
       "      shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneclass.fit(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the algorithm on the test set\n",
    "\n",
    "fraud_pred = oneclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1 4034]\n",
      " [   1 6166]]\n"
     ]
    }
   ],
   "source": [
    "# Check the number of outliers predicted by the algorithm\n",
    "\n",
    "unique, counts = np.unique(fraud_pred, return_counts=True)\n",
    "print (np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert fraud_pred to dataframe for ease of operation\n",
    "\n",
    "fraud_pred = pd.DataFrame(fraud_pred)\n",
    "fraud_pred= fraud_pred.rename(columns={0: 'prediction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  3930\n",
      "FN:  6070\n",
      "FP:  104\n",
      "TN:  96\n"
     ]
    }
   ],
   "source": [
    "# -1 is outlier, i.e. what we hope to be the anomaly\n",
    "TP = np.sum((Y_test['Malignant/Benign'] == 1) & (fraud_pred['prediction'] == -1))\n",
    "FN = np.sum((Y_test['Malignant/Benign'] == 1) & (fraud_pred['prediction'] == 1))\n",
    "FP = np.sum((Y_test['Malignant/Benign'] == 0) & (fraud_pred['prediction'] == -1))\n",
    "TN = np.sum((Y_test['Malignant/Benign'] == 0) & (fraud_pred['prediction'] == 1))\n",
    "\n",
    "print (\"TP: \", TP)\n",
    "print (\"FN: \", FN)\n",
    "print (\"FP: \", FP)\n",
    "print (\"TN: \", TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.39\n",
      "recall:  0.39\n",
      "Specificity:  0.48\n",
      "precision:  0.97\n",
      "F1:  0.56\n"
     ]
    }
   ],
   "source": [
    "# Performance Matrix\n",
    "accuracy = (TP+TN)/(TP+FN+FP+TN)\n",
    "print (\"Accuracy: \", np.round(accuracy, 2))\n",
    "recall = TP/(TP+FN)\n",
    "print (\"recall: \", np.round(recall, 2))\n",
    "specificity = TN/(TN+FP)\n",
    "print (\"Specificity: \", np.round(specificity, 2))\n",
    "precision = TP/(TP + FP)\n",
    "print (\"precision: \", np.round(precision, 2))\n",
    "F1 = 2/((1/precision) + (1/recall))\n",
    "print (\"F1: \", np.round(F1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get different results with a linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
